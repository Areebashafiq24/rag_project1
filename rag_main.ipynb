{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install markdown\n",
    "!pip install langchain\n",
    "!pip install pdfminer.six\n",
    "pip install InstructorEmbedding\n",
    "pip install sentence-transformers\n",
    "\n",
    "pip install --upgrade InstructorEmbedding\n",
    "pip install InstructorEmbedding langchain langchain-community faiss-cpu\n",
    "\n",
    "pip install InstructorEmbedding sentence-transformers\n",
    "pip install -U langchain-community\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "pip install InstructorEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"rajpurkar/squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING NECESSARY LIBRARIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import markdown\n",
    "from pdfminer.high_level import extract_text as extract_text_from_pdf\n",
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JUST CHECKING AND PRINTING DOC 1 TO SEE IF DATA IS LOADED CORRECTLY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset in 14.13 seconds\n",
      "Selected document: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the SQuAD dataset\n",
    "start_time = time.time()\n",
    "ds = load_dataset(\"rajpurkar/squad\")\n",
    "print(f\"Loaded dataset in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Select a single document for processing\n",
    "document_to_process = ds['train'][0]\n",
    "print(\"Selected document:\", document_to_process['context'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING DATASET "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZING MODEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMBEDDING AND INDEXING ALL DOCS USING FIASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset in 15.62 seconds\n",
      "Processed 10 documents in 29.46 seconds\n",
      "Initialized model in 4.81 seconds\n",
      "Created FAISS index in 4610.99 seconds\n",
      "Saved FAISS index in 1.04 seconds\n",
      "Embeddings and FAISS index created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def clean_markdown(text):\n",
    "    \"\"\"Clean Markdown syntax from text.\"\"\"\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\([^)]+\\)', r'\\1', text)\n",
    "    text = re.sub(r'\\*\\*([^*]+)\\*\\*', r'\\1', text)\n",
    "    text = re.sub(r'\\*([^*]+)\\*', r'\\1', text)\n",
    "    text = re.sub(r'__([^_]+)__', r'\\1', text)\n",
    "    text = re.sub(r'_([^_]+)_', r'\\1', text)\n",
    "    text = re.sub(r'!\\[[^\\]]]*]\\([^)]*\\)', '', text)\n",
    "    text = re.sub(r'#+\\s?', '', text)\n",
    "    text = re.sub(r'\\|', ' ', text)\n",
    "    text = re.sub(r'-{2,}', '', text)\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
    "    return text.strip()  # Strip extra spaces\n",
    "\n",
    "def process_context(entry, chunk_size, chunk_overlap):\n",
    "    \"\"\"Process a single context and return document chunks.\"\"\"\n",
    "    context = entry['context']\n",
    "    clean_context = clean_markdown(context)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_text(clean_context)\n",
    "    \n",
    "    processed_docs = []\n",
    "    for j, chunk in enumerate(docs):\n",
    "        metadata = {\n",
    "            \"Document ID\": entry['id'],\n",
    "            \"Chunk Number\": j + 1,\n",
    "        }\n",
    "        header = f\"Document ID: {entry['id']}\\n\"\n",
    "        for key, value in metadata.items():\n",
    "            header += f\"{key}: {value}\\n\"\n",
    "        chunk_with_header = header + chunk\n",
    "        processed_docs.append(chunk_with_header)\n",
    "    \n",
    "    return processed_docs\n",
    "\n",
    "# Parameters for text splitting\n",
    "chunk_size = 1200\n",
    "chunk_overlap = 100\n",
    "\n",
    "# Load the SQuAD dataset\n",
    "start_time = time.time()\n",
    "ds = load_dataset(\"rajpurkar/squad\")\n",
    "print(f\"Loaded dataset in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Process only the first 10 documents in the dataset\n",
    "start_time = time.time()\n",
    "processed_docs = []\n",
    "for entry in ds['train'].select(range(50000)):\n",
    "    processed_docs.extend(process_context(entry, chunk_size, chunk_overlap))\n",
    "print(f\"Processed 10 documents in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize the model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "start_time = time.time()\n",
    "model = SentenceTransformer(model_name)\n",
    "print(f\"Initialized model in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Initialize HuggingFaceEmbeddings\n",
    "hf_embedding = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "# Embed and index all the documents using FAISS\n",
    "start_time = time.time()\n",
    "db = FAISS.from_texts(processed_docs, hf_embedding)\n",
    "print(f\"Created FAISS index in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Save the indexed data locally\n",
    "start_time = time.time()\n",
    "db.save_local(\"faiss_AiDoc\")\n",
    "print(f\"Saved FAISS index in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(\"Embeddings and FAISS index created and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "sentence_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Assume 'processed_docs' contains the processed document texts\n",
    "embeddings = embedding_model.embed_documents(processed_docs)\n",
    "\n",
    "# Convert embeddings list to NumPy array\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the FAISS index\n",
    "faiss.write_index(index, \"faiss_index.bin\")\n",
    "\n",
    "# Save additional data\n",
    "metadata = {\n",
    "    \"processed_docs\": processed_docs,\n",
    "    \"model_name\": model_name\n",
    "}\n",
    "\n",
    "with open(\"faiss_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metadata, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(\"faiss_index.bin\")\n",
    "\n",
    "# Load metadata\n",
    "with open(\"faiss_metadata.pkl\", \"rb\") as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "processed_docs = metadata[\"processed_docs\"]\n",
    "model_name = metadata[\"model_name\"]\n",
    "\n",
    "# Re-initialize the embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "sentence_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Create the FAISS vector store\n",
    "faiss_index = FAISS(embedding_function=embedding_model, index=index, docstore=None, index_to_docstore_id=None)\n",
    "\n",
    "# Now you can use `faiss_index` as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-Neo model used to generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Query: What is the capital of France?\n",
      "Documents:\n",
      "Document ID: 5733be284776f41900661182\n",
      "Document ID: 5733be284776f41900661182\n",
      "Chunk Number: 1\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary. Document ID: 5733be284776f4190066117f\n",
      "Document ID: 5733be284776f4190066117f\n",
      "Chunk Number: 1\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary. Document ID: 5733be284776f41900661180\n",
      "Document ID: 5733be284776f41900661180\n",
      "Chunk Number: 1\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary. Document ID: 5733be284776f41900661181\n",
      "Document ID: 5733be284776f41900661181\n",
      "Chunk Number: 1\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary. Document ID: 5733be284776f4190066117e\n",
      "Document ID: 5733be284776f4190066117e\n",
      "Chunk Number: 1\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "Answer:\n",
      "Document ID: 5733be284776f41900661182\n",
      "Chunk Number: 1\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "Answer:\n",
      "Document ID: 5733be284776f41900661181\n",
      "Chunk Number: 1\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "Answer:\n",
      "Document ID: 5733be284776f41900661182\n",
      "Chunk Number: 1\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bern\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "\n",
    "# Load the GPT-Neo model and tokenizer\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"  # You can use \"EleutherAI/gpt-neo-2.7B\" if you have enough resources\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Set the pad token to be the eos token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_response(query, retrieved_docs, max_input_length=1024, max_new_tokens=512):\n",
    "    # Combine the query and retrieved documents\n",
    "    input_text = f\"Query: {query}\\nDocuments:\\n{retrieved_docs}\\nAnswer:\"\n",
    "\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_input_length)\n",
    "    \n",
    "    # Generate the response\n",
    "    output = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode the output\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the capital of France?\"\n",
    "# Combine the chunks of the top retrieved document as a single string\n",
    "retrieved_docs = \" \".join([chunk for chunk in processed_docs[:5]])  # Using the top 5 chunks as an example\n",
    "\n",
    "response = generate_response(query, retrieved_docs)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
